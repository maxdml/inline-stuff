Test on L2 cache:
L2 specification:
256KB, 64 B cache line, 8-way associative, 512 sets

Array type: Single-dimensional
Elements: 16384
Data type: uint64_t
Total size of array: 128 KB (Half the size of L2 cache)
L2 Prefetching: disabled

All the array elements were accessed sequentially for 10 iterations to see how many L2 cache references and misses were recorded.
The result was as expected. According to the result, there were 2048 references for all the iterations and 2048 misses for the first iteration and then no of misses lesser and lesser for the rest of the iterations. For some of the iterations at the end, they increase somewhat.   
Since, granularity of cache fill is a cache line which is 64 bytes, we expect 8 uint64_t type elements to be loaded at once. As there are a total of 16384 such elements, there should be 16384 / 8 = 2048 references for all the iterations which is as given by the results also. But the no. of misses don't exactly match the expectations. Since, no of elements are half the size of L2, once all the elements have been loaded into L2 during the first iteration, there should not be any more misses for the subsequent iterations. But the reason of these misses might be that the core is maintaining many other data values in L2 which might be causing some of the array element cache lines to be evicted.   

One surprising thing here about the L3 cache is that there are never any misses. There should atleast be 1 for the very first iteration when the data is loaded from memory.
